{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Assignment: timeseries analysis and extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Import the packages. I'll do this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  # This is new\n",
    "from scipy import stats  # This also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Heathrow dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Open the file a prepare the data the same way we did in the lesson. Let me do this for you as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "dfh = pd.read_csv('../data/csv/gsod-heathrow.csv', index_col=1, parse_dates=True)\n",
    "\n",
    "# Missing values\n",
    "dfh = dfh.replace([99.99, 999.9, 9999.9], np.nan)\n",
    "dfh = dfh.reindex(pd.date_range(dfh.index[0], dfh.index[-1], freq='D'))\n",
    "\n",
    "# Period selection\n",
    "dfh = dfh.loc['1973':'2024']\n",
    "\n",
    "# Outlier filtering\n",
    "dfh['PRCP'] = dfh['PRCP'].where(dfh['PRCP'] < 10) \n",
    "\n",
    "# Keep the variables we want\n",
    "dfh = dfh[['TEMP', 'MAX', 'MIN', 'PRCP']].copy()\n",
    "\n",
    "# Convert units\n",
    "dfh[['TEMP', 'MAX', 'MIN']] = (dfh[['TEMP', 'MAX', 'MIN']] - 32) * 5/9\n",
    "dfh['PRCP'] = dfh['PRCP'] * 25.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "**Now create two samples:**\n",
    "- **`s1` is the sample of daily average temperatures in July from 1973-1987 (15 years)**\n",
    "- **`s2` is the sample of daily average temperatures in July from 2010-2024 (15 years)**\n",
    "\n",
    "Verify that both samples have the same number of days. How many are that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**Plot an histogram for each of these distributions, using the same bins for boths. If you are a bit ambitious, plot both histograms on the same graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**Fit a Gaussian PDF for each of these samples, and plot the two PDFs on a single plot.** *Hint: you should aim at creating a plot similar to [this famous IPCC plot](https://archive.ipcc.ch/ipccreports/tar/wg1/fig2-32.htm).*\n",
    "\n",
    "**Interpret the plot. Are there changes in the central value, in the spread of the distribution?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**E: Compute (i) the empirical and (ii) the theoretical probability based on the PDF for a day to exceed 25°C average temperature in both samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "**Interpret what you computed. What is the increased risk ratio for hot days (>25°) between both periods?** *Hint: I'm expecting a statement similar to \"Hot days have become x times more likely between period 1 and 2.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Sometimes, it's also cold in the UK. **Count the average number of days per year where the daily *maximal* temperature is below freezing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "**How many freezing days were there on average before 2000? And after?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Precipitation and streamflow at Chew valley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Go to the download page, and download the catchment daily rainfall (`53004_cdr.csv`) and gauged daily flow (`53004_gdf.csv`) from the server. Put the files in your `data/csv` folder.\n",
    "\n",
    "**Open the files in a text editor of your choice, or in jupyterlab itself. Note the header of the file, and how the data is structured.**\n",
    "\n",
    "Reading these files requires to skip the header (`skiprows`). We will also ignore the second column in each file, and put the two timeseries (streamflow and precipitation) into one dataframe for simplicity. Let me do all this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/53004_cdr.csv', skiprows=19, index_col=0, parse_dates=True)\n",
    "df.index.name = 'Date'\n",
    "\n",
    "df.columns = ['cdr', 'gdf']\n",
    "\n",
    "# Check that time series is complete\n",
    "assert len(df) == len(pd.date_range(df.index[0], df.index[-1], freq='D')) \n",
    "assert df['cdr'].isnull().sum() == 0\n",
    "\n",
    "# Read streamflow and add it to the dataframe\n",
    "df_gdf = pd.read_csv('../data/csv/53004_gdf.csv', skiprows=19, index_col=0, parse_dates=True)\n",
    "df_gdf.columns = ['flow', '-']\n",
    "df['gdf'] = df_gdf['flow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Explore the dataset. Read the documentation for the [catchment rainfall](https://nrfa.ceh.ac.uk/catchment-rainfall) and the [gauged streamflow](https://nrfa.ceh.ac.uk/gauged-daily-flow-data). What are the units of the two variables?**\n",
    "\n",
    "Let me plot the two datasets over a year for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2000'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "By chance, the two variables have a similar range of values. It is however cleaner to plot them on separate axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2000'].plot(secondary_y='gdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Or, with more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots()\n",
    "ax1.plot(df.loc['2000']['cdr'], label='Rainfall');\n",
    "ax2 = plt.twinx()\n",
    "ax2.plot(df.loc['2000']['gdf'], color='C1', label='Streamflow- right');\n",
    "plt.legend();\n",
    "ax1.set_ylabel('Rainfall (mm/day)');\n",
    "ax2.set_ylabel('Streamflow (m3/s)');\n",
    "plt.title('Year 2000');\n",
    "\n",
    "# Combine legends\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "**Now, instead of plotting the daily rainfall, plot the 5-day rolling mean of the rainfall. Repeat for the year 2012.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**Plot the average daily streamflow and precipitation on one single plot. It's probably a good idea to smooth the data with a rolling average before grouping for clarity.** *Hint: the x-axis should show day of year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "**Plot the percentage of missing values for both cdr and gdr variable per year over the entire period. Plot both variabls for the time period (2 calendar years) around the period where data is missing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "**With a web search, find out what happened in Chew Magna and Bristol in July 1968 and in the rest of UK later that year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "**Run an empirical return levels analysis for *maximal annual daily rainfall* at Chew. Your goal is to do a plot similar to the final plot you did in the lesson. For precipitation, it's a good idea to use log axes on both the x- and y-axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "**Extend the x-axis range to [1, 1100] using `ax.set_xlim([1, 1100])`.**\n",
    "\n",
    "**Qualitative analysis: based on the plot, visually extrapolate the trend formed by all the points excluding the last two extreme events. Estimate the expected return period for an event exceeding 100 mm, assuming these two events had not occurred.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
